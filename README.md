# Natural-Language-Processing-with-Disaster-Tweets
## Описание проекта
Этот проект направлен на классификацию твитов на предмет их принадлежности к категории катастрофических или некатастрофических. Используя методы обработки естественного языка (NLP) и машинного обучения, модель обучается на предоставленных данных и делает предсказания для тестового набора.

## Стек технологий
- Python
- pandas
- nltk
- scikit-learn
- matplotlib
- wordcloud

## Установка зависимостей
Перед запуском проекта убедитесь, что все необходимые библиотеки установлены. Вы можете установить их с помощью pip.

## Данные
В проекте используются два CSV-файла:
- train.csv — обучающий набор данных, содержащий тексты твитов и их метки (катастрофические или некатастрофические).
- test.csv — тестовый набор данных для предсказания.

## Предобработка данных
1. Загрузка данных из CSV-файлов.
2. Удаление стоп-слов и не буквенных символов из текстов.
3. Приведение текста к нижнему регистру.
4. Удаление лишних пробелов.

## Обучение модели
Проект использует логистическую регрессию в качестве модели для классификации текстов. Обучение происходит в два этапа:
1. Использование CountVectorizer для векторизации текстов.
2. Использование TfidfVectorizer для векторизации текстов.

Оценка модели производится с использованием следующих метрик:
- Точность (Accuracy)
- Матрица ошибок (Confusion Matrix)
- Отчет о классификации (Classification Report)

## Результаты
По завершении обучения модель выведет на экран точность на обучающей и тестовой выборках, матрицу ошибок и отчет о классификации. Кроме того, будет создан файл submission.csv, содержащий предсказания для тестового набора.

## Итоги
Данный проект демонстрирует применение методов обработки естественного языка и машинного обучения для решения задачи классификации текстов. Модель может быть адаптирована для других задач, связанных с анализом текстов.
